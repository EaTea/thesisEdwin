%-----------------------------------------------------------------------------%
%Packages%
\documentclass[12pt, a4paper, twoside]{article}
\usepackage{amsmath, amsfonts, listings, amssymb, mathtools, amsthm} %Mathematical Expressions package
\usepackage{mathtools}
\usepackage[usenames, dvipsnames]{color} %Color naming packages
\usepackage[margin=2.5cm]{geometry}
\usepackage{float}
\usepackage{verbatim} %for code
\usepackage[pdftex]{graphics}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{thmtools}
\usepackage{tikz}
\usepackage{comment}
\usepackage[nottoc]{tocbibind}
\usepackage[square]{natbib}

\usetikzlibrary{arrows,shapes}

%Graphis Extensions
\DeclareGraphicsExtensions{.png, .jpg}
\parindent 0pt

% Predefined things such as commands, etc.

\newcommand{\aRel}[1] {
  \sim_{#1} 
}

\newcommand{\kripkeFrame}[2] {
  (#1, \aRel{#2})
}

\newcommand{\kripkeModel}[3] {
  (#1, \aRel{#2}, #3)
}

\newcommand{\frKripModel}[2] { % defined via Kripke Frame + valuation
  (#1, #2)
}

\newcommand{\actModel}[3]{
  (#1, \aRel{#2}, #3)
}

\newcommand{\frActModel}[2] { % defined via Kripke Frame + Pre
  (#1, #2)
}

\newcommand{\note}[1]{\textsc{\textbf{#1}}}
\newcommand{\Universal}{$\mathcal{U}$}
\newcommand{\modalLog}{$\mathcal{L}$}
\newcommand{\modLogInf}{$\mathcal{L}_\inf$}
\newcommand{\epActLog}{\modalLog$([\alpha])$}
\newcommand{\epActLogCommonKnowledge}{\modalLog$([\alpha],\box^{*})$}

%\newtheorem{defn}{Definition}
%\newtheorem{thm}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem*{remrk}{Remark}

% Drawings of frames

\tikzstyle{vertex}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt]
\tikzstyle{selected vertex} = [vertex, fill=red!24]
\tikzstyle{edge} = [draw,thick,-]
\tikzstyle{weight} = [font=\small]

%-----------------------------------------------------------------------------%
%Document%
\begin{document}

%\begin{comment}
%The literature review should be about 3000-5000 words long.
%I would probably aim for around 4000.
%You'll need about 5 to 10 papers. Aim for 10?
%\end{comment}

\tableofcontents

\vfill
\pagebreak

{\em My comments will be in italic.}

\section{Introduction}\label{intro}
{\em I've done my best to motivate my topic and give an overview of where I want
to take us up to.
I've added in a weird little example in \ref{intro_coinFlipping}.
What am I missing in motivating the topic well?
What should I add in and what doesn't work at the moment with motivating?
Also what should not be here?}
\subsection{Describing Information State}\label{intro_infoState}
The study of information aims to capture what information multiple agents know
and what they might be uncertain about.
The logical study of information, known as epistemic logic, produces models
describing complex knowledge and states of knowledge of multiple agents.
A related field, the logics of belief --- doxastic logic --- describes the
beliefs of agents in terms of models.\\
\\
Such models are most useful in communications systems and have applications in
artificial intelligence and game theory.
They afford a level of rigour and specificity that informal reasoning about
knowledge cannot provide.
We can make rigourous and verifiable claims about situations by using
formal models of information and beliefs.\\
\\
The change of information state via an update of information is a field that has
seen much attention recently.
Theorists have constructed models that capture an update and the changes of
information entials.
These models have progressively increased in their powers of description and the
accuracy of the updates they have modelled.
Executing this description to transform a model of knowledge from one model to
another has been previously well-defined.\\
\\
In a similar manner to models of knowledge, models of information updates can be
used to formally reason about updates.
The rigour of formalism is appealing for an application that aims to guarantee
security or verify that it fulfills a specification.
This formalism to formal, provable methods of software development,
communication protocol verification as well as economics and game theory.\\
\\
However, translating a formal model describing information update into an
implementation of communication between multiple agents is an unexplored
process.
It would be desirable to transform a formally correct and verifiable specification of
communication into an executable protocol within a real world system.
\subsection{Coin-Flipping Game}\label{intro_coinFlipping}
Consider a game being played between two friends (or agents), Angeline $(A)$
and Ben $(B)$.
The game involves flipping a coin, hiding the result from both $A$ and $B$ and
having both of them guess whether the coin is Heads $(H)$ or the coin is Tails
$(T)$.
We can describe some possible changes of the information or beliefs that $A$ and
$B$ hold throughout this game.
\begin{itemize}
	\item $A$ might be told $H$ by her friend Carol $(C)$
	\item $C$ tells $A$ {\em something} in front of $B$ --- $B$ is now unsure
	whether $A$ has been told $H$, $T$ or something entirely irrelevant 
	\item $B$ becomes suspicious that $A$ has looked at the coin without his
	knowledge, but he is not sure
	\item $B$ goes to the bathroom, and $A$ sneaks a peek without him knowing.
	When he comes back, he is unaware that $A$ knows whether $H$ or $T$ is true.
\end{itemize}
This literature review considers the relevant writings and logics to describe
this situation, and the changes in the situation.
We will consider what information we can currently model and how we can model
updates and actions.
We will note what has not been explored in the fields and compare frameworks'
differing approaches and strengths.

\section{Epistemic Modal Logic}\label{epistemic}
{\em This section was just supposed to be talking about Modal Logic.
This is mainly my own ramblings trying to define Modal Logic nicely to the
reader, without the mathematics or relations.
How does it sound at the moment?
Have I made any sweeping misinformations, and if so what are they?
Is this section even valuable?}\\
\\
In the coin-flipping game, we can make the following observations.
\begin{itemize}
	\item $A$ considers $H$ to be possible, as well as $T$ to be possible
	\item $B$ also considers $H$ to be possible, and also considers $T$ to be possible
\end{itemize}
In order to capture and describe this state of knowledge in a formal manner, we
first turn to modal logic.
\subsection{Modal Logic}\label{epistemic_modal}
% talk about Kripke's work and Modal logic
Modal logic presents a formal framework for expressing sentiential notions, or
modalities in propositions.
These modalities qualify sentences and statements to express notions of
necessity, time, belief or knowledge.\citep{blackburn2002modal}\\
\\
Consider the statement ``It must rain today" and contrast it with ``It
might rain today".
The two qualifying statements (``must" and ``might") allow us differing notions
of the modality of necessity.
Modal logic provides us with a framework to express and describe these
notions, which we refer to as modalities.\\
\\
The most common modal logics are ``propositional modal logics", which are
propositional logic augmented with modalities.
These modal logics fulfil a minimal set of axioms, the weakest of these logics
being $\mathcal{K}$.
These axioms impose properties upon our modalities and thus reflect the kinds of
statements we wish to express.
\subsubsection{Kripke Semantics}\label{epistemic_kripke}
{\em I felt like Kripke Semantics were really important to have.
What do you think?
I think their discussion informs the reader about the meaning behind the models
we work with but perhaps I haven't really gone through it properly.}\\
\\
These mathematical descriptions and axioms allow us to specify our modalities
and logics, but the interpretation and meaning of the formal descriptions is
unclear.
Kripke introduces a ``possible worlds" or frame semantics to allow us to better
model our modalities. \citep{blackburn2002modal} \\
\\
In the context of logic, it is the semantics that allow us to interpret our
models and turn them from mathematical descriptions to meaningful models.
Kripke semantics have become the most common semantics for describing and
interpreting modal systems since they were introduced.\\
\\
We can then model situations of modalities as ``possible worlds" which are
related to, and can access other possible worlds.
Our modalities become operators on ``possible worlds" that can then state what
is true at a specific world.\\
\\
Kripke semantics give us a framework to make sense of the models we have
designed and impose a specific interpretation upon them.
However, modal logic and Kripke semantics are together still too weak to
describe and model knowledge or belief.\\
\\
We could formalise the statements ``$A$ knows $H$ is true" and ``$A$ knows $H$
is false" in certain modal logics such as $\mathcal{K}$.
Problematically, they could be part of a model where these statements would be
considered consistent in these logics.\\
\\
Modal logic is thus too general a framework; we need to establish what
properties knowledge has, and impose them as axioms for our logical relations of
epistemic logic.
We need to correct this weakness in our modal logic by formally specifying the
modalities that reflect knowledge and belief.
\subsection{Epistemic and Doxastic Logic}\label{epistemic_logics}
{\em I hope the axioms I've stated below make sense and are okay from a
	semantic or epistemic point of view.}\\
\\
In order to reason about our modalities in a sensible fashion, we place
conditions upon the modalities.
These conditions correspond to adding in extra axioms into our modal logic
system. \citep{hoek2008dynamic}\\
\\
In epistemic logic, the modality we are most concerned with is that of knowing.
We add the following five conditions upon our modality of knowledge
\begin{enumerate}
	\item if $A$ knows that the sky is cloudy $(\phi)$ and $A$ knows that if
	$\phi$ then it will rain $\gamma$, then if $A$ knows $\phi$ then $A$ knows
	$\gamma$.\\
	This condition corresponds to the axiom formally labelled {\bf K}.
	\item for every possibility that is consistent with $A$'s knowledge, if $\phi$
	is true then $A$ must know $\phi$.\\
	This is a principle known as {\bf N}.
	Together with {\bf K} they form the minimum set of conditions for a
	propositional modal logic.
	The weakest modal logic, known as $\mathcal{K}$ fulfills just these
	properties, and no more.
	\item if $A$ knows $\phi$ then $\phi$ is true.\\
	This condition corresponds to the axiom of truth, formally labelled {\bf T}.
	\item if $A$ knows $\phi$ then $A$ knows that she knows $\phi$.\\
	This condition corresponds to the ``positive introspection" axiom, labelled 
	as {\bf 4}.
	\item if $A$ does not know $\phi$ then $A$ knows that she does not know
	$\phi$.\\
	This condition corresponds to the ``negative introspection" axiom, labelled 
	as {\bf 5}.
\end{enumerate}
Together, these axioms form the system {\bf S5}.
{\bf S5} is the modal logic for dealing with the modality of knowledge and is
most commonly employed in epistemic logic.\\
\\
Replacing axiom {\bf T} (if an agent knows $\phi$ then $\phi$ must be true) with
the axiom {\bf D} allows us to deal with the modality of belief.
In the context of belief, {\bf D} states that if $A$ believes that $\phi$ then
$A$ considers $\phi$ a possibility.
This modal logic has been labelled {\bf KD45} and is usually used in the context
of doxastic logic, or the logic of belief.\\
\\
In the context of knowledge especially, {\bf 5} seems unreasonably strong.
That an agent knows what they don't know isn't particularly feasible in many
real world situations involving humans.
However, many artifical agents are aware of what they do not know, and thus
{\bf 5} is a reasonable axiom to impose when reasoning about artificial agents
or programs.
Thus, {\bf S5} most suitably captures information and relates possible
worlds of information back in the most sensible manner, hence its continued use
as the set of axioms of choice for epistemic modal logic. \citep{hoek2008dynamic}\\
\\
We can successfully describe $A$ and $B$'s knowledge in our game of coins using
the modalities provided in epistemic knowledge.
{\bf S5} affords us a rigourous formal logic for describing situations regarding
information.\\
\\
But what if their friend, $C$, announces ``The coin is Heads up" (that is,
$C$ announces $H$)?
Both epistemic and doxastic logic cannot describe the {\em change} in knowledge that
$C$'s announcement will entail.
Furthermore, we have no formal process to say how the situation has changed.\\
\\
This deficiency raises the following questions:
\begin{itemize}
	\item How do we describe this change in a formal manner?
	\item What reasonings can we make about the state of information after this
	change?
	\item Is there an operation that allows us to change the state of information
	from the pre-change state to the post-change state?
\end{itemize}

\section{Public Announcement Logic}\label{pal}
{\em I like this section, but am I citing the right papers?
Anything I'm missing?}\\
\\
To model the announcement of facts and information, we turn to the use of public
announcement logic.
Public announcements are announcements to multiple agents of facts.
They are a kind of informative update --- perhaps the most basic kind.\\
\\
Public announcement logic was first proposed independently by both Plaza and
Gerbrandy and Groeneveld. \citep{plaza2007public,gelbrandy1997reasoning}
They were later augmented by the work of Baltag, Moss and Solecki through the
addition of common knowledge. \citep{baltag1998lpa}
Public announcements are informational updates of true facts that change the
knowledge state amongst multiple agents.\\
\\
Public announcement of a fact $\phi$ cause all worlds where $\phi$ was
invalid to ``disappear" from our model.
It is thus quite easy to model the execution of a public announcements.
The execution simply causes all worlds that are no longer consistent with the
announcement to ``disappear" from our model of a given situation.\\
\\
Public announcements capture changes in information, such as $C$ saying to
$A$ and $B$ that the coin is $H$.
Another possible update is $A$ being allowed to see the coin's state, and
telling $B$ ``I guess you didn't know that the coin is actually heads up".\\
\\
These changes can be successful or unsuccessful, depending on whether the fact
that was announced is true after its announcement.
For example, if $A$ makes the (truthful) announcement that $H$, then this
announcement is successful since $H$ will be true after the announcement.\\
\\
Conversely, an announcement from $A$ that ``I know that you {\em don't} know $H$
and the coin is $H$" will be false after the announcement, since $A$'s
announcement has changed the knowledge state to invalidate her
announcement.
Therefore, the second example is an unsuccessful update.\\
\\
By using public announcement logic we can describe these announcements of
information.
We have a framework to describe and change the state of information amongst our
agents before and after announcements of facts.
Public announcement logic will allow us to model $C$ telling $A$ and $B$ in a
public fashion that $H$ is true.\\
\\
In terms of dynamic epistemic logic, however, there could be many more kinds of
updates that we have yet to consider.
Re-examining our game of heads and tails yields scenarios that we cannot
describe:
\begin{itemize}
	\item What about $A$ cheating and learning $H$ or $T$ without $B$'s knowledge?
	\item What about $B$ beginning to suspect $A$ of cheating?
	\item What if $C$ was to whisper (in front of $B$) whether the coin was $H$
	or $T$?
\end{itemize}
These are things public announcement logic cannot describe, and our inability to
model them raises more questions:
\begin{itemize}
	\item what other kinds of epistemic (or informative) updates exist?
	\item how can we describe other epistemic updates in a sensible manner?
	\item what kind of an execution is required for a more nontrivial update?
\end{itemize}

\section{Epistemic Actions and Action Models} \label{estAct}
We can now successfully capture the simple act of announcing a fact.
However, in public announcements, we cannot capture certain epistemic actions,
such as
\begin{itemize} 
  \item $C$ whispers to $A$ that $H$ is true and $B$ sees her whisper
  \item $C$ whispers to $A$ that $H$ is true without $B$ seeing
  \item $B$ suspects $A$ of cheating, but he isn't sure if she's cheated
\end{itemize}
Let us aim to generalise the ideas behind public announcements to capture other
informative updates.\\
\\
We will now constrain our agents' behaviours to only being able to accept facts.
They will not worry about changing facts, and if facts do change we will take it
as something that causes our agents knowledge systems to simply crash.\\
\\
We will examine two constrasting approaches to model these epistemic updates.
First, we examine the approach of van Ditsmarsch in constructing epistemic
actions.
\subsection{Epistemic Relational Actions} \label{epi_acts}
{\em According to \citep{hoek2008dynamic} the papers I'm referring toshould be
	the ones that Hans used to construct relational actions.
The problems that they pointed out were the things that I noticed whilst reading
through the book, hence why I've citepd it a few times.}\\
\\
van Ditsmarsch approaches epistemic actions from a syntactical point of view,
aiming to create a language to specify actions in.
His work in consutrcting an epistemic action syntax draws from some of the
syntax of established languages such as propositional dynamic
logic.\citep{ditmarsch99knowledge,ditmarsch2002dga}\\
\\
We will label his language as $\mathcal{L}_{!}$.
Within $\mathcal{L}_{!}$ van Ditsmarsch provides operations to make valid
epistemic statements, and further extends the language with dynamic or
action-oriented constructs.
These include the ability to test a proposition, to update a group of agents'
knowledge and to make a non-deterministic choice between actions.\\
\\
$\mathcal{L}_{!}$ presents a way to describe complex actions, and indeed we can
express and describe all the actions we've discussed in the previous sections.
We can formally describe actions such as cheating, or a private
announcement to $B$ that $H$ is true that's seen by $A$.\\
\\
However, reasoning about epistemic actions in their current form is difficult.
Indeed, the interpretations of an epistemic action are non-trivial to
understand.
Moreover, van Ditsmarsch, van der Hoek and Kooi present problems with
representing complex uncertainties with $\mathcal{L}_{!}$ that make it difficult
to reason about what $A$ and $B$ know after an action takes place.\\
\\
As an example, given two actions where a choice between actions $\Omega$ and
$\Gamma$ occurs, in which $B$ learns that $A$ learns either of $p \land q$ or
$p \land \neg q$ respectively.
We can see that $B$ should know that $A$ knows $p$ after either of $\Omega$ or
$\Gamma$ occurring.
In order to recognise this, we need a generalisation of our rules on what is
true after an action is executed.
Unfortunately, to generalise this principle and allow us to reason this out is
not provided in $\mathcal{L}_{!}$.\citep{hoek2008dynamic}\\
\\
This motivates our exploration of the work of Baltag, Moss and Solecki, who construct
another framework to model epistemic updates.
van Ditsmarsch, van der Hoek and Kooi note that this framework naturally
overcomes this problem by having the idea of accessibility between action
outcomes encoded into the model itself.
\subsection{Epistemic Action Models} \label{act_mods}
{\em Am I citing the right things in this section? I feel like these are the
	right papers and they're being citepd in the right places.}\\
\\
As an alternative to approaching epistemic actions syntactically, Baltag, Moss
and Solecki examine epistemic actions from a modelling point of view.
They aim to construct epistemic Action Models, which resemble the possible
worlds models of Kripke semantics. \citep{baltag1998lpa}
\footnote{Action Models resemble the possible worlds models of Kripke semantics,
but there were some discrepancies which meant they were not entirely equivalent.
Aucher resolves this and restores the symmetry between the models, allowing us
to reason about the actions within Action Models. \citep{aucher09revisited}}
This ``possible actions" model addresses the problems that van Ditsmarsch, van
der Hoek and Kooi highlighted with epistemic actions.\\
\\
Baltag and Moss extend the Action Models they proposed with Solecki into classes
of Action Models, which they term action signatures. \citep{baltag2005programs}
They formalise general descriptions of actions, such as announcements, lying,
suspicion and other epistemic updates.
As an example, they generalise all public announcements to a single structure,
showing the superior expressivity of Action Models.
They also specify a syntax for discussing actions of a given action signature,
allowing them to generate the logic of public announcements in its entirety.
Within this syntax, the Action Model structures are used as syntactical objects.
Like van Ditsmarsch's Epistemic Actions, Baltag and Moss' syntax borrows from
previous logics of dynamics and change.\\
\\
Action Models, being updates in themselves, are also define a method of
execution that is well-understood.
The execution will update a model of knowledge from a pre-update to a
post-update state.
Unfortunately, the cost of action model execution (that is, to transform a state
of information to a new state using an update specified by an action model) is
quite high.
It involves taking a Cartesian product of all possible actions.
This indicates that, given $N$ possible actions in an Action Model, $N^2$
actions must be computed in the new state of information before the model can
be refined.

\subsubsection{Comparison to Relational Epistemic Actions} \label{epi_compare}
{\em Do the citations here look legit?}\\
\\
Both Relational Epistemic Actions and Action Models describe a larger range of
epistemic updates for our game of heads and tails.
The examples we chose earlier, regarding $C$ telling $A$ about the state of the
coin, or $B$ becoming suspicious of $A$ can be expressed using either framework.
What, then, is the real difference between employing Action Models, as opposed
to Relational Epistemic Actions?\\
\\
van Ditsmarsch, van der Hoek and Kooi, as well as Baltag and Moss independently
note that the ``possible actions" of Action Models  are actually relational
epistemic actions.
In their own review of Action Models, van Ditsmarsch, van der Hoek and Kooi
motivate this with an example. \citep{hoek2008dynamic,baltag2005programs}\\
\\
They consider the non-deterministic choice of 3 possible actions which are
indistinguishable externally.
As an example, $B$ might learn that $A$ knows either of $H$ or $T$, or has
learnt nothing at all.
Since $B$ does not know which of these actions could occur, each of these
epistemic updates is a possible action.\\
\\
They show that it is possible to express this uncertainty in a manner quite similar
to an Action Model.
Similarly, the corresponding Action Model of whether $B$ learns of $A$'s
knowledge of $H$, $T$ or nothing new is quite easily interpreted in a manner
akin to Relational Epistemic Actions.
Their general result is that relational actions can be expressed as action
models, and vice versa.
As van Ditsmarsch, van der Hoek and Kooi have already shown, it is in reasoning
with these models that the models differ.\\
\\
Notably, Relational Epistemic Actions and Action Models suffer from the same
weakness, in that they are only externally describe an update of information.
Their execution and specification are only useful to a third-party viewer, and
how agents internal to a system update their knowledge is not clear.
This is one of several weaknesses in current dynamic epistemic logic, with
regards to translating a specification of an informational update into an
implementable series of messages.\\
\\
It is in their reasoning that Action Models and Relational Epistemic Actions
differ most.
Action Models give us a notion of uncertainty between actions in a manner
similar to Kripke semantics, allowing us to use a formally established framework
to reason about dynamic updates.
This allows us to reason about our updates and their effects in a more natural
and well-understood way.\\
\\
Conversely, van Ditsmarsch's Relational Epistemic Actions give us a syntax that
is perhaps more natural than the one Baltag and Moss define.
Baltag and Moss are note that it is non-standard to use the structures from
Kripke semantics inside a syntax.
In the context of interpreting and making sensible updates, however, it is
perhaps less useful to have abstraction at the cost of useful interpretations,
suggesting that Action Models are a more interesting way to model epistemic
updates.
Indeed, it would appear that at the moment Action Models are experiencing more
interest compared to Relational Epistemic Actions, as we explore in the next
section.

\subsection{Extensions of Action Models}
{\em This section is kinda bad.
It's the most open-ended, where I've tried to compare, discuss and point out
	stuff.
I feel like it might be rambling or have lost a lot of focus.
I want to refactor it, but are there any particular points that you like?
I've been trying to communicate the current gaps in Action Models as we know
them...?}\\
\\
Action Models, when first introduced, were a concept that could be used to make
formal reasonings about actions in a similar way to Kripke semantics.
Progress in this area has added a syntax that uses Action Models as syntactic
objects, improved the expressivity of Action Models and investigated the
synthesis of Action Models.
Much of the discussion has showed how powerful Action Models are as a way for a
third party to reason about an informational update, and improved what kind of
informational updates we can capture.\\
\\
Baltag and Moss define a powerful syntax for constructing epistemic programs.
Their syntax is as powerful as van Ditsmarsch's in Relational Epistemic Actions,
being able to express sequences of epistemic actions or make a non-deterministic
choice between two established action models.
The only objection to their syntax, as raised earlier, is the curious use of
the semantic structures within a syntax.
It is also notable that the operations of composition and non-deterministic
choice can be as costly as Action Model execution, generating $N \times M$
possible actions, given two Action Models of size $N$ and $M$
respectively.\citep{baltag2005programs}\\
\\
van Benthem, van Eijck and Kooi extend Action Models for a new language to
handle communication and change.
Their main contribution here is to improve Action Model languages with notions
of group knowledge and iterations of an action model's execution.
This logic of communication and change uses previous logics of change as a basis
and proceeds to interpret it in an epistemic fashion.\citep{benthem2006lcc}\\
\\
In a recent contribution, Hales describes an algorithm that can synthesise arbitrary
Action Models.
Thus, if an Action Model exists that can take one model of modal logic into
another, this algorithm will be able to synthesise it.
This contribution is especially notable due to it generalising outside of
epistemic logic, to any modal logic system.
Thus it is possible to transform any modal logic model into another modal logic
model using Action Models.\citep{hales13synthesis}\\
\\
This work shows how, for any system of logic, we can transform one model into
another, notwithstanding some constraints upon what transformations are
possible.
The state of the art in Action Models and this section of Dynamic Epistemic
Logic is thus focused upon improving descriptions of information updates.
None of this research discusses how an Action Model can be implemented in a
real-world system.
Instead, Action Models have become better at describing changes, but how they
should be implemented is still unclear.

\subsubsection{Possible Future Work}
{\em I discuss some stuff from \citep{benthem2006lcc} a few times, but it's
	interspersed with \citep{bollig07mps}.
Should I change this around a bit?
It might be a bit too unstructured to follow properly?}\\
\\
Whilst the expressivity and operators in languages involving Action Models are
improving (as in \citep{benthem2006lcc}) Action Models are treated as purely
descriptive objects.
We note two avenues of research that, as of yet, do not appear to have been
investigated.
\begin{enumerate}
	\item Action Models are external descriptions in their nature; they are only used as
	descriptions, so how an agent who is participating in the communications
	should use them is unclear
	\item Action Models have not been translated into real-world systems and no
	known method exists to change an Action Model into an implemented sequence of
	messages. The actual cost of Action Model execution in a real-world system has
	never been measured due to no-one ever implementing an Action Model.
\end{enumerate}
Thus, Action Models only describe changes, and the execution and expense of
their execution is not taken into account.
This makes it less clear how useful an Action Model would be, without a method
of transforming a description into an implementation.\\
\\
Perhaps the closest related work regarding the expense of an update might be
Bollig et. al's findings regarding communications and message passing with
dynamic logics.
The dynamic logics they utilise in their work are the same as those that van
Benthem et. al base their own work upon.
Their findings show that message passing sequences need to be of exponential
length in order to capture logical statements. \citep{bollig07mps}\\
\\
However, Bollig et. al approach message passing from the perspective of dynamic
logic.
Although van Benthem et. al use the same dynamic logic in their system, the
programs and information updates that they aim to capture might be more specific
than the general cases Bollig et. al appear to be interested in.
Thus, even though it is for a message passing sequence, there may be
structures of Action Models specifically that we can capture.\\
\\
As it stands, Bollig et. al's research is tangential to the work of van Benthem
et. al.
With regards to Action Models, the work thus far is confined to being only
useful for expressing specification of change, and whether or not such
specification implemented remains to be seen.\\
\\
van Benthem et. al also note that they had not interested themselves with methods of
generating Action Models from an ``atomic" set of Action Models. \citep{benthem2006lcc}
They lay out their intuitions about how to generate Action Models and the class
of epistemic updates, but decide not to investigate this avenue of enquiry.
This presents another unexplored avenue regarding Action Models' generation from
an atomic set of Action Models, as well as what these atomic sets are.\\
\\
Thus, although Action Models are appropriate for descriptions there is not
method to take an Action Model and transform it into an implementation.
In addition to the two areas of further investigation that we noted at the
beginning of this section, we now observe a third area for further work.
That is, it is unclear how we could generate all Action Models from a
set of atomic Action Models.

\section{Conclusion} \label{conc}
{\em I've been trying to come to a big overarching wrap up of the review;
	summarising the major points and missing parts of research.
What could be improved about this part?
Does it concisely cover what I've been discussing?
Is there a good impression that I've gotten to the state of the art, and also
showed things that people haven't yet investigated?}\\
\\
We have arrived at being able to describe the changes and updates in our game of
heads and tails by employing frameworks of logic.
We have begun at the beginning of modal logic, motivating the use of epistemic
logic and logics of changing information.
In the process, we have examined different epistemic updates, from public
annoucncements to more general updates like private announcements and agents
becoming suspicious.
We have come to the current forefront of dynamic epistemic updates --- the
power to formally describe change in modal logic systems.\\
\\
We have also explored some of the gaps and possible avenues that are now open.
We noted three issues that we believe have not been investigated by current
research.
Firstly, current literature still does not speak much of how to translate Action Models
into implementable, practical updates.
Secondly, how Action Models can be generated is unclear, especially with regards to what
the basic ``atoms" for generation are, as well as what operations are necessary
to generate any Action Model.
Finally, Action Models are descriptive in nature, and are only useful for an
external party.
The process for an agent involved in the change to utilise an Action Model to
execute an informative update is also unclear.\\
\\
In order to move towards realising Action Model execution in a real-world,
applied system, the issues surrounding the expense of execution should be resolved.
Generating all Action Models from ``atomic" models, and how Action Models can be
decomposed into these atoms should also be investigated.

\bibliographystyle{plainnat}
\bibliography{litReview}

\end{document}
