%-----------------------------------------------------------------------------%
%Packages%
\documentclass[10pt, a4paper, twoside]{article}
\usepackage{amsmath, amsfonts, listings, amssymb, mathtools, amsthm} %Mathematical Expressions package
\usepackage{mathtools}
\usepackage[usenames, dvipsnames]{color} %Color naming packages
\usepackage[margin=1.5cm]{geometry}
\usepackage{float}
\usepackage{verbatim} %for code
\usepackage[pdftex]{graphics}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{thmtools}
\usepackage{tikz}
\usepackage{comment}

\usetikzlibrary{arrows,shapes}

%Graphis Extensions
\DeclareGraphicsExtensions{.png, .jpg}
\parindent 0pt

% Predefined things such as commands, etc.

\newcommand{\aRel}[1] {
  \sim_{#1} 
}

\newcommand{\kripkeFrame}[2] {
  (#1, \aRel{#2})
}

\newcommand{\kripkeModel}[3] {
  (#1, \aRel{#2}, #3)
}

\newcommand{\frKripModel}[2] { % defined via Kripke Frame + valuation
  (#1, #2)
}

\newcommand{\actModel}[3]{
  (#1, \aRel{#2}, #3)
}

\newcommand{\frActModel}[2] { % defined via Kripke Frame + Pre
  (#1, #2)
}

\newcommand{\note}[1]{\textsc{\textbf{#1}}}
\newcommand{\Universal}{$\mathcal{U}$}
\newcommand{\modalLog}{$\mathcal{L}$}
\newcommand{\modLogInf}{$\mathcal{L}_\inf$}
\newcommand{\epActLog}{\modalLog$([\alpha])$}
\newcommand{\epActLogCommonKnowledge}{\modalLog$([\alpha],\box^{*})$}

\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem*{remrk}{Remark}

% Drawings of frames

\tikzstyle{vertex}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt]
\tikzstyle{selected vertex} = [vertex, fill=red!24]
\tikzstyle{edge} = [draw,thick,-]
\tikzstyle{weight} = [font=\small]

%-----------------------------------------------------------------------------%
%Document%
\begin{document}

%\begin{comment}
%The literature review should be about 3000-5000 words long.
%I would probably aim for around 4000.
%You'll need about 5 to 10 papers. Aim for 10?
%\end{comment}

\tableofcontents

\vfill
\pagebreak


\section{Introduction}\label{intro}
\subsection{Describing Information State}\label{intro_infoState}
The study of information aims to capture what information multiple agents know
and what they might be uncertain about.
The logical study of information, known as epistemic logic, produces models
describing complex knowledge and states of knowledge of multiple agents.
A related field, the logics of belief --- doxastic logic --- describes the
beliefs of agents in terms of models.\\
\\
Such models are most useful in communications systems and have applications in
artificial intelligence and game theory.
They afford a level of rigour and specificity that informal reasoning about
knowledge cannot provide.\\
\\
The change of information state via an update of information is a field that has
seen much attention recently.
Theorists have found models that describe updates and changes of information with
increasing expressivity.
Executing such a model to update a state of information has been well-defined.
However, no framework for the execution of these models exists, and the current
cost of execution is theoretically non-trivial.
\subsection{Coin-Flipping Game}\label{intro_coinFlipping}
Consider a game being played between two friends (or agents), Angeline $(A)$
and Ben $(B)$.
The game involves flipping a coin, hiding the result from both $A$ and $B$ and
having both of them guess whether the coin is Heads $(H)$ or the coin is Tails
$(T)$.
$A$ or $B$ might be told $H$ or $T$ by their friend Carol $(C)$ or perhaps they
learn this themselves through sneaking a glance.\\
\\
This literature review considers the relevant writings and logics to describe
this situation.
We will consider what information we can currently model and how we can model
updates and actions.
We will note what has not been explored in the fields and compare frameworks'
differing approaches and strengths.
%\begin{itemize}
%  \item A motivation for this study; to define a framework for epistemic actions
%  using minimal ``atoms"
%  \item Provide a basis for exploring different updates and dynamic epistemic
%  logic
%  \item Proposed direction would be to model epistemic updates in the context of
%  message passing systems
%  \item Need to provide a clear motivation for study in this area
%  \item Have to show {\em why} we'd want to specify and realise epistemic
%  updates
%\end{itemize}

\section{Epistemic Modal Logic}\label{epistemic}
In the coin-flipping game, we can make the following observations.
\begin{itemize}
	\item $A$ considers both $H$ and $T$ to be possible
	\item $B$ considers both $H$ and $T$ to be possible
\end{itemize}
In order to capture and describe this state of knowledge in a formal manner, we
first turn to modal logic.
\subsection{Modal Logic}\label{epistemic_modal}
% talk about Kripke's work and Modal logic
Modal logic presents a formal framework for expressing sentiential notions, or
modalities in propositions.
These modalities qualify sentences and statements to express notions of
necessity, time, belief or knowledge.\\
\\
Consider the statement ``It must rain today" and contrast it with ``It
might rain today".
The two qualifying statements (``must" and ``might") allow us differing notions
of necessity.
Modal logic provides us with a framework to express and describe these
notions, which we refer to as modalities.\\
\\
The most common modal logics are ``propositional modal logics", which are
propositional logic augmented with modalities.
These modal logics fulfil a minimal set of axioms, the weakest of these logics
being $\mathcal{K}$.
From this minimal set of axioms, we can give our modalities additional
properties that reflect the kinds of statements we wish to express.
\subsubsection{Kripke Semantics}\label{epistemic_kripke}
These mathematical descriptions and axioms allow us to specify our modalities
and logics, but interpreting these specifications is difficult.
Kripke introduces a ``possible worlds" or frame semantics to allow us to better
model our modalities.\\
\\
We can then model situations of modalities as ``possible worlds" which are
related to, and can access other possible worlds.
Our modalities become operators on ``possible worlds" that can then state what
is true at a specific world.\\
\\
Kripke semantics give us a framework to make sense of the models we have
designed and impose a specific interpretation upon them.
However, modal logic and Kripke semantics are together still too weak to
describe and model knowledge or belief.\\
\\
We could formalise the statements ``$A$ knows $H$ is true" and ``$A$ knows $H$
is false" in certain modal logics such as $\mathcal{K}$.
Problematically, they could be part of a model where these statements would be
considered consistent in these logics.\\
\\
Modal logic is thus too general a framework; we need to establish what axioms we
will use in our logical relations for epistemic logic.
We need to correct this weakness in our modal logic by moving to the specific
modalities that reflect knowledge and belief.
\subsection{Epistemic and Doxastic Logic}\label{epistemic_logics}
In order to reason about our modalities in a sensible fashion, we place
conditions upon the modalities.
These conditions correspond to adding in extra axioms into our modal logic
system.\\
\\
In epistemic logic, the modality we are most concerned with is that of knowing.
We add the following five conditions upon our modality of knowledge
\begin{enumerate}
	\item if $A$ knows that the sky is cloudy $(\phi)$ and $A$ knows that if
	$\phi$ then it will rain $\gamma$, then if $A$ knows $\phi$ then $A$ knows
	$\gamma$.\\
	This condition corresponds to the axiom formally labelled {\bf K}.
	\item for every possibility that is consistent with $A$'s knowledge, if $\phi$
	is true then $A$ must know $\phi$.\\
	This is a principle known as {\bf N}.
	Together with {\bf K} they form the minimum set of conditions for a
	propositional modal logic.
	\item if $A$ knows $\phi$ then $\phi$ is true.\\
	This condition corresponds to the axiom of truth, formally labelled {\bf T}.
	\item if $A$ knows $\phi$ then $A$ knows that she knows $\phi$.\\
	This condition corresponds to the ``positive introspection" axiom, labelled 
	as {\bf 4}.
	\item if $A$ does not know $\phi$ then $A$ knows that she does not know
	$\phi$.\\
	This condition corresponds to the ``negative introspection" axiom, labelled 
	as {\bf 5}.
\end{enumerate}
Together, these axioms form the system {\bf S5}.
{\bf S5} is the modal logic for dealing with the modality of knowledge and is
most commonly employed in epistemic logic.\\
\\
Replacing axiom {\bf T} (if an agent knows $\phi$ then $\phi$ must be true) with
the axiom {\bf D} allows us to deal with the modality of belief.
In the context of belief, {\bf D} states that if $A$ believes that $\phi$ then
$A$ considers $\phi$ a possibility.
This modal logic has been labelled {\bf KD45} and is usually used in the context
of doxastic logic, or the logic of belief.\\
\\
In the context of knowledge especially, $5$ seems unreasonably strong.
That an agent knows what they don't know isn't particularly feasible in many
real world situations.
However, {\bf S5} most suitably captures information and relates possible
worlds of information back in the most sensible manner, hence its continued use
as the set of axioms of choice for epistemic modal logic.\\
\\
We can successfully describe $A$ and $B$'s knowledge in our game of coins using
the modalities provided in epistemic knowledge.
{\bf S5} affords us a rigourous formal logic for describing situations regarding
information.\\
\\
But what if their friend, $C$, announces ``The coin is actually Heads" (that is,
$C$ announces $H$)?
Both epistemic and doxastic logic cannot describe the change in knowledge that
$C$'s announcement will entail.
Furthermore, we have no formal process to say how the situation has changed.\\
\\
This deficiency raises the following questions:
\begin{itemize}
	\item How do we describe this change in a formal manner?
	\item What reasonings can we make about the state of information after this
	change?
	\item Is there an operation that allows us to change the state of information
	from the pre-change state to the post-change state?
\end{itemize}

\section{Public Announcement Logic}\label{pal}
To model the announcement of facts and information, we turn to the use of public
announcement logic.
Public announcements are announcements to multiple agents of facts.
They are a kind of informative update --- perhaps the most basic kind.\\
\\
Public announcement logic was first proposed independently by both Plaza and
Gerbrandy and Groeneveld.
They were later augmented by the work of Baltag, Moss and Solecki through the
addition of common knowledge.
Public announcements are informational updates of true facts that change the
knowledge state amongst multiple agents.\\
\\
Public announcement of a fact $\phi$ cause all worlds where $\phi$ was
invalid to ``disappear" from our model.
In effect, our public announcements are quite easy to model their execution
since it is simply causing all worlds that are no longer valid to ``disappear"
from our model of a given situation.\\
\\
Public announcements capture changes in information, such as $C$ saying to
$A$ and $B$ that the coin is $H$.
Another possible update is $A$ being allowed to see the coin's state, and
telling $B$ ``I guess you didn't know that the coin is actually heads up".\\
\\
These changes can be successful or unsuccessful, depending on whether the fact
that was announced is true after its announcement.
For example, if $A$ makes the (truthful) announcement that $H$, then this
announcement is successful since $H$ will be true after the announcement.\\
\\
Conversely, an announcement from $A$ that ``I know that you {\em don't} know $H$
and the coin is $H$" will be false after the announcement, since $A$'s
announcement has changed the knowledge state to invalidate her
announcement.
Therefore, the second example is an unsuccessful update.\\
\\
By using public announcement logic we can describe these announcements of
information.
We have a framework to describe and change the state of information amongst our
agents before and after announcements of facts.
Public announcement logic will allow us to model $C$ telling $A$ and $B$ in a
public fashion that $H$ is true.
\\
In terms of dynamic epistemic logic, however, there could be many more kinds of
updates that we have yet to consider.
Re-examining our game of heads and tails yields scenarios that we cannot
describe:
\begin{itemize}
	\item What about $A$ cheating and learning $H$ or $T$ without $B$'s knowledge?
	\item What about $B$ suspecting $A$ of cheating, even though she hasn't?
	\item What if $C$ was to whisper (in front of $B$) whether the coin was $H$
	or $T$?
\end{itemize}
These are things public announcement logic cannot describe, and our inability to
model them raises more questions:
\begin{itemize}
	\item what other kinds of epistemic (or informative) updates exist?
	\item how can we describe other epistemic updates in a sensible manner?
	\item we managed to model public announcement execution by specifying that it
	was simply the announcement of facts about the world, which is a reasonably
	easy update to the state of agent knowledge. What kind of an execution is
	required for a more nontrivial update?
\end{itemize}

\section{Epistemic Actions and Action Models} \label{estAct}
We can now successfully capture the simple act of announcing a fact.
However, in public announcements, we cannot capture certain epistemic actions,
such as
\begin{itemize} 
  \item $C$ whispers to $A$ that $H$ is true and $B$ sees her whisper
  \item $C$ whispers to $A$ that $H$ is true without $B$ seeing
  \item $B$ suspects $A$ of cheating, but he isn't sure if she's cheated
\end{itemize}
Let us aim to generalise the ideas behind public announcements to capture other
informative updates.\\
\\
We will examine two constrasting approaches to model these epistemic updates.
First, we examine the approach of van Ditsmarsch in constructing epistemic
actions.
\subsection{Epistemic Relational Actions} \label{epi_acts}
van Ditsmarsch approaches epistemic actions from a syntactical point of view,
aiming to create a language to specify actions in.
His work in consutrcting an epistemic action syntax draws from some of the
syntax of established languages such as propositional dynamic logic.\\
\\
We will label his language as $\mathcal{L}_{!}$.
Within $\mathcal{L}_{!}$ van Ditsmarsch provides operations to make valid
epistemic statements, and further extends the language with dynamic or
action-oriented constructs.
These include the ability to test a proposition, to update a group of agents'
knowledge and to make a non-deterministic choice between actions.\\
\\
$\mathcal{L}_{!}$ presents a way to describe complex actions, and indeed we can
express and describe all the actions we've discussed in the previous sections.
We can formally describe actions such as cheating, or a private
announcement to $B$ that $H$ is true that's seen by $A$.\\
\\
However, reasoning about epistemic actions in their current form is difficult.
Indeed, the interpretations of an epistemic action are non-trivial to
understand.
Moreover, van Ditsmarsch, van der Hoek and Kooi present problems with
representing complex uncertainties with $\mathcal{L}_{!}$ that make it difficult
to reason about what $A$ and $B$ know after an action takes place.\\
\\
As an example, given two actions where a choice between actions $\Omega$ and
$\Gamma$ occurs, in which $B$ learns that $A$ learns either of $p \land q$ or
$p \land \neg q$ respectively.
We can see that $B$ should know that $A$ knows $p$ after either of $\Omega$ or
$\Gamma$ occurring.
In order to recognise this, we need a generalisation of our rules on what is
true after an action is executed.
Unfortunately, to generalise this principle and allow us to reason this out is
not provided in $\mathcal{L}_{!}$.\\
\\
This motivates our exploration of the work of Baltag and Moss in constructing
another framework to model epistemic updates.
van Ditsmarsch, van der Hoek and Kooi note that this framework naturally
overcomes this problem by having the idea of accessibility between action
outcomes encoded into the model itself.
\subsection{Epistemic Action Models} \label{act_mods}
As an alternative to approaching epistemic actions syntactically, Baltag, Moss
and Solecki examine epistemic actions from a modelling point of view.
They aim to construct epistemic Action Models, which resemble the possible
worlds models of Kripke semantics.
This ``possible actions" model addresses the problems that van Ditsmarsch, van
der Hoek and Kooi highlighted with epistemic actions.\\
\\
Baltag and Moss extend the Action Models they proposed with Solecki into classes
of Action Models, which they term action signatures.
They formalise general descriptions of actions, generating the class of
public announcements or the class of lying actions.
They also specify a syntax for discussing actions of a given action signature,
allowing them to generate the logic of public announcements in its entirety.
Like epistemic actions, Baltag and Moss' syntax borrows from propositional
dynamic logic.\\
\\
Action Models, being semantic updates in themselves, are also provided with a
method of execution that is well-understood.
Unfortunately, the cost of action model execution (that is, to transform a state
of information to a new state using an update specified by an action model) is
quite high, as it involves taking a Cartesian product of all possible actions.
This indicates that, given $N$ possible actions, $N^2$ actions must be computed
in the new state of information before the model can be refined.
\subsubsection{Comparison to Relational Epistemic Actions}
van Ditsmarsch, van der Hoek and Kooi, as well as Baltag and Moss independently
note that the ``possible actions" of Action Models  are actually relational
epistemic actions.
In their own review of Action Models, van Ditsmarsch, van der Hoek and Kooi
motivate this with an example.\\
\\
They consider the non-deterministic choice of 3 possible actions which are
indistinguishable externally.
As an example, $B$ might learn that $A$ knows either of $H$ or $T$, or has
learnt nothing at all.
Since $B$ doesn't know which of these actions could occur, each of these
epistemic updates is a possible action.\\
\\
They show that it is possible to express this uncertainty in a manner quite similar
to an Action Model.
Similarly, the corresponding Action Model of whether $B$ learns of $A$'s
knowledge of $H$, $T$ or nothing new is quite easily interpreted in a manner
akin to Relational Epistemic Actions.
Their general result is that relational actions can be expressed as action
models, and vice versa.
As van Ditsmarsch, van der Hoek and Kooi have already shown, it is in reasoning
with these models that the models differ.\\
\\
Action Models give us a notion of uncertainty between actions in a manner
similar to Kripke semantics, allowing us to use a formally established framework
to reason about dynamic updates.
This allows us to reason about our updates and their effects in a more natural
and well-understood way.\\
\\
Conversely, van Ditsmarsch's Relational Epistemic Actions give us a syntax that
is perhaps more natural than the one Baltag and Moss define.
Baltag and Moss are note that it is non-standard to use the structures from
Kripke semantics inside a syntax.
In the context of interpreting and making sensible updates, however, it is
perhaps less useful to have abstraction at the cost of useful interpretations,
suggesting that Action Models are a more interesting way to model epistemic
updates.
Indeed, it would appear that at the moment Action Models are experiencing more
interest compared to Relational Epistemic Actions, as we explore in the next
section.

\subsection{Extensions of Action Models}
Baltag and Moss define a powerful syntax for constructing epistemic programs.
Their syntax is as powerful as van Ditsmarsch's, being able to express sequences
of epistemic actions or make a non-deterministic choice between two established
action models.
The only objection to their syntax, as raised earlier, is the curious use of
the structures of Kripke semantics within a syntax.
It is also notable that the operations of composition and non-deterministic
choice can be as costly as Action Model execution, generating $N \times M$
possible actions given two Action Models of size $N$ and $M$ respectively.\\
\\
van Benthem, van Eijck and Kooi extend Action Models for a new language to
handle communication and change.
Their main contribution here is to improve the expressivity of their language
with the addition of common knowledge and novel applications of the Kleene star
to finite automata.
This logic of communication and change uses propositional dynamic logic as a basis
and proceeds to interpret it in an epistemic fashion.\\
\\
In a recent contribution, Hales et. al showed that given two modal states $S_1$
and $S_2$ that each described a multi-agent system, an Action Model $\mathcal{A}$
could be constructed, such that executing $\mathcal{A}$ on $S_1$ produced $S_2$.
This contribution is especially notable due to it generalising outside of
epistemic logic, to any modal logic system.\\
\\
As 
% Describe epistemic actions
% Describe epistemic Action Models
% Compare the two --- can one be expressed in the other?
% What are some of the programs that are coming out of each?
% Talk about James' work

%\section{Action Models}\label{actModels}
%\begin{itemize}
%  \item reiterate the weaknesses of what we've seen so far and wonder if we can
%  cover them
%  \item introduce the concept of an Action Model
%\end{itemize}
%\subsection{Action Models Definition}\label{actModelDefn}
%\begin{itemize}
%  \item first covered in BMS1998
%  \item give the definition of a model as a Kripke frame with a valuation
%  \item motivate the model itself, the reasoning you can do with it
%  \item BMS claim you can model message passing with their constructs, but they
%  give no ideas about it
%  \item furthermore it's all about what the omniscient 3rd party sees, not what
%  the agents themselves can see
%\end{itemize}
%\subsection{Extending PDL}\label{actModelExtends}
%\begin{itemize}
%  \item BM2004 suggests an epistemic program, similar to PDL
%  \item gives us a powerful syntax similar to PDL
%  \item what are the consequences?
%  \item what can we express, and what updates can't we express?
%  \item comparison of using PDL for message passing and the consequences of this
%  \item notice that we're not sure what the smallest set of things to generate
%  all Action Models are
%  \item we don't know how we can realise Action Models
%  \item if PDL is anything to go by we could be using exponential states to
%  communicate things, is not good
%\end{itemize}
%
%\section{Conclusion}\label{conclusion}
%\begin{itemize}
%  \item Resummarise what this literature review has discussed
%  \item Make any comparisons and comments upon whether we can realise an
%  epistemic update
%  \item remotivate my topic; no-one has yet thought about how the agents can
%  realise a specified update and what the complexity of this is
%\end{itemize}

\end{document}
